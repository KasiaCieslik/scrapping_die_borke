{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/kasia/Python Projects/scrapping_die_borke')\n",
    "import pandas as pd\n",
    "import time\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dateutil import parser\n",
    "import re\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import sqlite3\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.surf-und-segelschule-mueggelsee.de/?Wetterdaten'\n",
    "\n",
    "def download_weather_data(url):\n",
    "    response = requests.get(url) # \n",
    "    html = response.content\n",
    "    scraped = BeautifulSoup(html,'html.parser')\n",
    "    return scraped\n",
    "\n",
    "scraped= download_weather_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## save beaufitful soup to txt\n",
    "file1 = open(\"../src/test/scraped_raw.txt\",\"w\")\n",
    "file1.write(str(scraped))\n",
    "file1.close()\n",
    "\n",
    "## save list to txt\n",
    "\n",
    "d = []\n",
    "for data in scraped.find('div',class_=\"tbis-layout-cell layout-item-old-1\").find_all('tr'):\n",
    "        d.append(data.text)\n",
    "file1 = open(\"../src/test/for_test_extract_float_from_string.txt\",\"w\")\n",
    "file1.write(str(d))\n",
    "file1.close()\n",
    "\"\"\"\n",
    "def extract_float_from_string(string):\n",
    "    l = [float(x) for x in re.findall(\"\\d+\\.\\d+\", string)]\n",
    "    if len(l) == 1:\n",
    "        return l[0]\n",
    "    else:\n",
    "        return l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lastupdate': datetime.datetime(2020, 9, 16, 22, 8, 21),\n",
       " 'temp': 21.4,\n",
       " 'wind': 9.5,\n",
       " 'boen': 17.3,\n",
       " 'niederschlag': 0.0,\n",
       " 'feuchte': 74,\n",
       " 'luftdruck': 1018.1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"../src/test/scraped_raw.txt\",'r') as f:\n",
    "    soup = BeautifulSoup(f, \"html.parser\")\n",
    "parse_data(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_data(scraped):\n",
    "    d = []\n",
    "    for data in scraped.find('div',class_=\"tbis-layout-cell layout-item-old-1\").find_all('tr'):\n",
    "        d.append(data.text)\n",
    "    mapping = {}\n",
    "    mapping['lastupdate'] = parser.parse(d[0].split(': ')[1])\n",
    "    mapping['temp'] = extract_float_from_string(d[2])\n",
    "    mapping['wind'] = extract_float_from_string(d[3])[0]\n",
    "    mapping['boen'] = extract_float_from_string(d[3])[1]\n",
    "    mapping['niederschlag'] = extract_float_from_string(d[4])\n",
    "    mapping['feuchte'] = int(re.findall(\"\\d+\\\\d+\", d[5])[0])\n",
    "    mapping['luftdruck'] = extract_float_from_string(d[6])\n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db(database_name):\n",
    "    connection = sqlite3.connect(database_name)\n",
    "    cursor = connection.cursor()\n",
    "    #cursor.execute('DROP TABLE IF EXISTS weather')\n",
    "    sql_command = \"\"\"CREATE TABLE IF NOT EXISTS weather (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    lastupdate DATETIME,\n",
    "    temp REAL,\n",
    "    wind REAL,\n",
    "    boen REAL,\n",
    "    niederschlag REAL,\n",
    "    feuchte REAL,\n",
    "    luftdruck REAL)\"\"\"\n",
    "\n",
    "    cursor.execute(sql_command)\n",
    "    connection.close()\n",
    "    \n",
    "def insert_to_db_table(mapping,database_name):\n",
    "    connection = sqlite3.connect(database_name)\n",
    "    cursor = connection.cursor()\n",
    "    sql_command = \"\"\"INSERT INTO weather \n",
    "    (lastupdate, temp, wind, boen, \n",
    "    niederschlag, feuchte, luftdruck) \n",
    "    VALUES (:lastupdate,:temp,:wind,:boen,\n",
    "    :niederschlag,:feuchte,:luftdruck)\"\"\"\n",
    "\n",
    "    cursor.execute(sql_command,mapping)\n",
    "    connection.commit()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_db('data/scrap_die_borke.db')\n",
    "url = 'https://www.surf-und-segelschule-mueggelsee.de/?Wetterdaten'\n",
    "while True:\n",
    "    try:\n",
    "        get_data(url,'data/scrap_die_borke.db')\n",
    "        time.sleep(30)\n",
    "    except Exception as e:\n",
    "        print(\"File not accessible\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect(\"data/scrap_die_borke.db\")\n",
    "pd.read_sql(\"SELECT * FROM weather\",connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    scraped = download_weather_data(url)\n",
    "    mapping = parse_data(scraped)\n",
    "    insert_to_db_table(mapping,'data/scrap_die_borke.db')\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
